{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686d8fbd-7961-4681-b59c-3cbb62785931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 53, 110,  80, ...,  38,   0,   9],\n",
       "       [ 48, 104, 102, ...,  72,  67,  26],\n",
       "       [ 45,  67,  81, ...,  11,   0,   2],\n",
       "       ...,\n",
       "       [204, 215, 383, ...,  23,   8,  10],\n",
       "       [ 50, 116, 100, ...,  27,   9,  11],\n",
       "       [ 30,  47,  61, ...,  15,   0,   5]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"train.csv\")\n",
    "df2 = pd.read_csv(\"test.csv\")\n",
    "df1.values\n",
    "df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d7e3fe8-f4d2-49e9-bdbb-4431e627f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "np_array = np.array(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41996a2a-17dc-4123-9c4b-29d68b70aa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 24,  51,  44, ...,  27,   0,   3],\n",
       "       [ 22,  31, 214, ...,   0,   0,   2],\n",
       "       [ 84, 126, 239, ...,  24,   8,   9],\n",
       "       ...,\n",
       "       [268, 358, 277, ...,  47,   7,   5],\n",
       "       [ 81, 116,  90, ...,   9,   0,   2],\n",
       "       [118, 156, 197, ...,   0,   0,   5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3152573-ca16-4643-998e-6882de547dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS_0_9_CP</th>\n",
       "      <th>POS_10_19_CP</th>\n",
       "      <th>POS_20_29_CP</th>\n",
       "      <th>POS_30_39_CP</th>\n",
       "      <th>POS_40_49_CP</th>\n",
       "      <th>POS_50_59_CP</th>\n",
       "      <th>POS_60_69_CP</th>\n",
       "      <th>POS_70_79_CP</th>\n",
       "      <th>POS_80_89_CP</th>\n",
       "      <th>POS_90_CP</th>\n",
       "      <th>DTH_CUM_CP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>214</td>\n",
       "      <td>177</td>\n",
       "      <td>62</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84</td>\n",
       "      <td>126</td>\n",
       "      <td>239</td>\n",
       "      <td>194</td>\n",
       "      <td>159</td>\n",
       "      <td>171</td>\n",
       "      <td>125</td>\n",
       "      <td>74</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>107</td>\n",
       "      <td>339</td>\n",
       "      <td>287</td>\n",
       "      <td>139</td>\n",
       "      <td>147</td>\n",
       "      <td>110</td>\n",
       "      <td>71</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>86</td>\n",
       "      <td>201</td>\n",
       "      <td>206</td>\n",
       "      <td>202</td>\n",
       "      <td>240</td>\n",
       "      <td>317</td>\n",
       "      <td>225</td>\n",
       "      <td>138</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>125</td>\n",
       "      <td>124</td>\n",
       "      <td>104</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>268</td>\n",
       "      <td>358</td>\n",
       "      <td>277</td>\n",
       "      <td>415</td>\n",
       "      <td>355</td>\n",
       "      <td>332</td>\n",
       "      <td>215</td>\n",
       "      <td>107</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>81</td>\n",
       "      <td>116</td>\n",
       "      <td>90</td>\n",
       "      <td>145</td>\n",
       "      <td>118</td>\n",
       "      <td>113</td>\n",
       "      <td>70</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>118</td>\n",
       "      <td>156</td>\n",
       "      <td>197</td>\n",
       "      <td>215</td>\n",
       "      <td>114</td>\n",
       "      <td>114</td>\n",
       "      <td>83</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      POS_0_9_CP  POS_10_19_CP  POS_20_29_CP  POS_30_39_CP  POS_40_49_CP  \\\n",
       "0             24            51            44            51            60   \n",
       "1             22            31           214           177            62   \n",
       "2             84           126           239           194           159   \n",
       "3             65            76            80           110            82   \n",
       "4             99           107           339           287           139   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "1039          86           201           206           202           240   \n",
       "1040          80           102           125           124           104   \n",
       "1041         268           358           277           415           355   \n",
       "1042          81           116            90           145           118   \n",
       "1043         118           156           197           215           114   \n",
       "\n",
       "      POS_50_59_CP  POS_60_69_CP  POS_70_79_CP  POS_80_89_CP  POS_90_CP  \\\n",
       "0               75            72            61            27          0   \n",
       "1               46            24             9             0          0   \n",
       "2              171           125            74            24          8   \n",
       "3               81            55            49            56         34   \n",
       "4              147           110            71            37          0   \n",
       "...            ...           ...           ...           ...        ...   \n",
       "1039           317           225           138            48          0   \n",
       "1040            71            70            36             6          0   \n",
       "1041           332           215           107            47          7   \n",
       "1042           113            70            36             9          0   \n",
       "1043           114            83            19             0          0   \n",
       "\n",
       "      DTH_CUM_CP  \n",
       "0              3  \n",
       "1              2  \n",
       "2              9  \n",
       "3              7  \n",
       "4             12  \n",
       "...          ...  \n",
       "1039           7  \n",
       "1040           6  \n",
       "1041           5  \n",
       "1042           2  \n",
       "1043           5  \n",
       "\n",
       "[1044 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2f7ac6-0803-4830-b179-47d45b4bba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(df1.loc[:, \"POS_0_9_CP\":\"POS_90_CP\"].values),\n",
    "    torch.tensor(df1.loc[:, [\"DTH_CUM_CP\"]].values)\n",
    ")\n",
    "\n",
    "ds2 = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(df2.loc[:, \"POS_0_9_CP\":\"POS_90_CP\"].values),\n",
    "    torch.tensor(df2.loc[:, [\"DTH_CUM_CP\"]].values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13e0338-3426-4b45-b189-fa846725bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = ds1[: :]\n",
    "testX, testY = ds2[: :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ee7b24-8f43-4fc3-942d-3bba532cdc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX.to(torch.float64)\n",
    "trainY = trainY.to(torch.float64)\n",
    "testX = testX.to(torch.float64)\n",
    "testY = testY.to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25659a13-fd05-4638-8e7d-22845f64b579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 24.,  51.,  44.,  ...,  61.,  27.,   0.],\n",
       "        [ 22.,  31., 214.,  ...,   9.,   0.,   0.],\n",
       "        [ 84., 126., 239.,  ...,  74.,  24.,   8.],\n",
       "        ...,\n",
       "        [268., 358., 277.,  ..., 107.,  47.,   7.],\n",
       "        [ 81., 116.,  90.,  ...,  36.,   9.,   0.],\n",
       "        [118., 156., 197.,  ...,  19.,   0.,   0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c354a3-38c6-49c3-ac98-3d54d3a1cfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.],\n",
       "        [2.],\n",
       "        [9.],\n",
       "        ...,\n",
       "        [5.],\n",
       "        [2.],\n",
       "        [5.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "357b9512-69d4-4bde-8fe1-ee920a3572a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83520\n"
     ]
    }
   ],
   "source": [
    "#q1 : about how many bytes does trainX consume?\n",
    "print(trainX.nelement() * trainX.element_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a3f95c8-bc5b-4b53-8370-87c2bef70633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#q2 : what is the biggest difference we would have any one cell if we used float16 instead of float64?\n",
    "biggest_val = -1.0\n",
    "for cell in trainX:\n",
    "    # print(cell)\n",
    "    float16_X = cell.to(torch.float16)\n",
    "    float16_X = float16_X.to(torch.float64)\n",
    "    # print(torch.sum(float16_X))\n",
    "    diff = abs(float16_X - cell)\n",
    "    # torch.sum(diff)\n",
    "    # print(torch.sum(diff).item())\n",
    "    curr_val = torch.sum(diff).item()\n",
    "    if curr_val > biggest_val:\n",
    "        biggest_val = curr_val\n",
    "print(biggest_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57452f0a-8ea7-4686-9338-34f8ce196f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3 : is a CUDA GPU available on your VM?\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "883dbb3c-42c3-44f7-8dd1-7fa86c1430f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0040],\n",
       "        [0.0040],\n",
       "        [0.0040],\n",
       "        [0.0040],\n",
       "        [0.0040],\n",
       "        [0.0040],\n",
       "        [0.0300],\n",
       "        [0.0300],\n",
       "        [0.0300],\n",
       "        [0.0300]], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = torch.tensor([\n",
    "        [0.0040],\n",
    "        [0.0040],\n",
    "        [0.0040],\n",
    "        [0.0040],\n",
    "        [0.0040],\n",
    "        [0.0040], # POS_50_59_CP\n",
    "        [0.0300], # POS_60_69_CP\n",
    "        [0.0300],\n",
    "        [0.0300],\n",
    "        [0.0300]\n",
    "], dtype=trainX.dtype)\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dad0736e-e5be-464d-a858-e89cb8555c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.844"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4 : what is the predicted number of deaths for the first census tract?\n",
    "\n",
    "(testX[:1, 0:10] @ coef).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6295bf4-fa96-4c40-9ddf-0328a01a3bcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.073632183908048"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5 : what is the average number of predicted deaths, over the whole testX dataset?\n",
    "\n",
    "(testX[:, :] @ coef).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6cbc02f-4ed1-47be-bbf8-dd8e309377a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    return (x**2) - (8 * x) + 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84a09e90-d5fa-4676-b82c-17502926853e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6 : first, what is y when x is a tensor containing 0.0?\n",
    "\n",
    "x = torch.tensor(0.0, requires_grad=True)\n",
    "y = f(x)\n",
    "float(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c631e91f-0e49-4bca-85e7-addd263777d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9999430179595947"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#q7 : what x value minimizes y?\n",
    "\n",
    "optimizer = torch.optim.SGD([x], lr=0.1)\n",
    "\n",
    "for epoch in range(50):\n",
    "    y=f(x)\n",
    "    plt.plot(x.detach(), y.detach(), \"ro\", markersize = 3)\n",
    "    y.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "e06762c7-ad18-4582-bbca-6bdf6539e7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44, 10])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "94cf6be0-92fe-4d99-b577-2f416d39c755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([44, 1])"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "16f690d5-15e7-4222-9ba1-e4e951e75a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = torch.zeros((10, 1), dtype=torch.float64)\n",
    "trainX @ coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "0de38999-f21f-4918-a651-d5a7103e6cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(244.4773, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#q8 : what is the MSE (mean-square error) when we make predictions \n",
    "# using this vector of zero coefficients?\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "coef = torch.zeros((10, 1), dtype=torch.float64)\n",
    "predictions = trainX @ coef\n",
    "mean_sqr_err = loss_fn(predictions, trainY)\n",
    "print(mean_sqr_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "3c9db82a-dbcc-4ff4-aad5-bbd8fcb4805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(174.1361, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(133.7573, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(110.4349, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(96.8258, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(88.7514, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(83.8339, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(80.7202, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(78.6403, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(77.1557, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(76.0169, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(75.0816, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(74.2688, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(73.5320, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(72.8448, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(72.1920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(71.5646, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(70.9574, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(70.3675, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(69.7928, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(69.2322, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(68.6847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(68.1499, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(67.6271, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(67.1161, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(66.6164, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(66.1277, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(65.6498, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(65.1823, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(64.7250, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(64.2776, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(63.8399, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(63.4116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(62.9925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(62.5824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(62.1810, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(61.7881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(61.4034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(61.0269, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(60.6583, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(60.2973, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(59.9439, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(59.5977, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(59.2588, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(58.9267, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(58.6015, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(58.2828, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(57.9707, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(57.6648, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(57.3651, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(57.0713, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(56.7835, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(56.5013, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(56.2247, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(55.9535, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(55.6877, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(55.4270, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(55.1714, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(54.9207, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(54.6748, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(54.4336, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(54.1970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(53.9649, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(53.7371, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(53.5136, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(53.2943, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(53.0790, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.8677, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.6603, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.4567, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.2567, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.0604, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(51.8676, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(51.6782, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(51.4922, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(51.3095, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(51.1300, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.9536, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.7802, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.6099, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.4425, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.2779, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.1161, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.9570, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.8006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.6468, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.4956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.3468, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.2004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.0564, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.9147, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.7753, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.6381, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.5031, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.3702, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.2393, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.1105, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.9837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.8587, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.7357, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.6145, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.4951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.3775, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.2617, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.1475, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.0349, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.9240, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.8147, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.7069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.6006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.4958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.3925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.2905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.1900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.0908, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.9930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.8964, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.8012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.7071, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.6143, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.5227, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.4323, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.3430, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.2548, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.1678, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.0818, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.9968, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.9129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.8300, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.7481, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.6672, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.5872, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.5082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.4300, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.3528, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.2764, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.2009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.1263, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.0524, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.9794, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.9072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.8357, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.7651, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.6951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.6259, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.5574, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.4897, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.4226, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.3562, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.2904, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.2253, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.1609, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.0971, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.0339, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.9713, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.9094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.8480, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.7871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.7269, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.6672, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.6080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.5494, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.4913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.4337, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.3766, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.3200, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.2640, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.2083, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.1532, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.0985, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.0443, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.9906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.9372, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.8843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.8319, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.7798, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.7282, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.6770, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.6262, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.5757, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.5257, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.4760, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.4267, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.3778, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.3293, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.2811, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.2332, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.1857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.1385, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.0452, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.9990, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.9532, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.9077, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.8624, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.8175, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.7729, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.7286, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.6846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.6408, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.5974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.5542, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.5113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.4687, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.4264, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.3843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.3425, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.3009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.2596, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.2186, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.1778, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.1372, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.0969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.0568, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.0170, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.9774, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.9380, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.8988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.8599, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.8212, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.7827, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.7445, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.7064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.6686, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.6309, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.5935, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.5563, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.5192, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.4824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.4458, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.4094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.3731, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.3371, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.3012, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.2655, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.2300, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.1947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.1596, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.1246, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.0552, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.0208, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.9865, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.9524, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.9185, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.8847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.8511, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.8177, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.7844, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.7513, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.7183, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.6855, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.6528, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.6203, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.5880, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.5558, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.5237, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.4918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.4600, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.4284, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.3970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.3656, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.3344, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.3034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.2725, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.2417, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.2110, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.1805, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.1501, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.1199, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.0898, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.0598, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.0300, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.0002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.9706, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.9411, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.9118, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.8826, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.8535, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.8245, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.7956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.7669, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.7382, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.7097, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.6814, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.6531, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.6249, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.5969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.5689, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.5411, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.5134, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.4858, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.4583, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.4310, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.4037, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.3765, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.3495, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.3226, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.2957, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.2690, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.2423, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.2158, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.1894, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.1631, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.1369, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.1107, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.0847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.0588, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.0330, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.0073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.9816, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.9561, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.9307, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.9053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.8801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.8549, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.8299, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.8049, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.7801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.7553, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.7306, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.7060, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.6815, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.6571, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.6328, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.6086, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.5844, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.5604, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.5364, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.5125, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.4887, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.4650, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.4414, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.4178, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.3944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.3710, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.3477, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.3245, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.3014, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.2784, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.2554, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.2325, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.2097, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.1870, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.1644, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.1418, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.1194, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.0970, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.0747, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.0524, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.0302, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.0082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.9862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.9642, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.9424, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.9206, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.8989, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.8773, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.8557, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.8342, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.8128, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.7915, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.7702, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.7490, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.7279, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.7069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.6859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.6650, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.6442, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.6234, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.6027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.5821, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.5615, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.5410, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.5206, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.5003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.4800, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.4598, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.4397, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.4196, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.3996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.3797, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.3598, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.3400, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.3202, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.3006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.2809, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.2614, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.2419, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.2225, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.2032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.1839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.1646, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.1455, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.1264, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.1073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.0884, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.0695, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.0506, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.0318, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.0131, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.9944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.9758, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.9573, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.9388, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.9204, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.9020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.8837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.8655, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.8473, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.8292, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.8111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.7931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.7751, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.7572, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.7394, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.7216, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.7039, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.6862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.6686, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.6511, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.6336, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.6161, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.5987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.5814, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.5641, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.5469, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.5297, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.5126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.4956, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.4786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.4616, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.4447, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.4279, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.4111, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.3944, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.3777, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.3611, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.3445, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.3280, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.3115, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.2951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.2787, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.2624, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.2461, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.2299, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.2137, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.1976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.1816, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.1656, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.1496, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.1337, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.1178, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.1020, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.0862, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.0705, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.0549, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.0392, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.0237, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.0082, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.9927, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.9773, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.9619, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.9466, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.9313, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.9160, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.9009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.8857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.8706, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.8556, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.8406, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.8256, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.8107, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.7958, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.7810, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.7663, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.7515, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.7368, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.7222, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.7076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.6931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.6786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.6641, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.6497, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.6353, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.6210, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.6067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5925, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5783, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5641, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5500, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5360, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5219, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5080, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.4940, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.4801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.4663, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.4525, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.4387, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.4250, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.4113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#q9 : what is the MSE over the training data, using the coefficients \n",
    "# resulting from the above training?\n",
    "\n",
    "ds = torch.utils.data.TensorDataset(trainX, trainY)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=50, shuffle=True)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "coef = torch.zeros((10, 1), dtype=torch.float64, requires_grad=True)\n",
    "optimizer = torch.optim.SGD([coef], lr=0.000002)\n",
    "\n",
    "for epoch in range(500):\n",
    "    for trainX, trainY in dl:\n",
    "        predictions = trainX @ coef\n",
    "        loss = loss_fn(predictions, trainY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(loss_fn(trainX @ coef, trainY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "cca077e1-6ba5-4cd7-afac-e1daa3027219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(36.0920, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.3290, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.1195, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.9193, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.7271, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.5422, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.3640, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.1921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.0261, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.8654, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.7097, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.5586, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.4120, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.2693, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1305, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.9953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.8634, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7347, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.6089, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4860, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3658, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2481, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1328, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9090, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8003, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4860, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3849, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2855, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1878, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9972, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9042, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8126, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7224, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6337, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5463, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4602, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3753, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2918, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1282, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0482, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9694, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8916, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8150, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7394, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6648, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5913, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5188, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4473, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3768, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3072, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2385, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1708, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1040, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0380, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9730, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9088, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8454, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7829, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7212, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6603, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5409, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4824, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4246, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3675, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2556, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2007, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1465, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0930, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0402, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9880, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9365, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8857, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8355, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7369, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6886, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6409, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.5937, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.5471, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.5011, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4557, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.4108, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.3665, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.3227, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.2795, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.2368, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1529, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.1117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0711, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.0309, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9912, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9519, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.9132, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8749, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.8370, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7627, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.7262, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6901, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6544, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.6192, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5843, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5499, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.5159, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4823, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4490, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.4162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3516, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.3198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2885, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2575, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.2268, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1665, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1369, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.1076, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0786, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0499, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(24.0216, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9659, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9385, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.9114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8581, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8319, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.8059, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7803, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7549, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7298, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.7050, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6804, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6562, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6321, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.6083, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5848, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5615, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5385, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.5157, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4931, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4708, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4487, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4269, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.4053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3839, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3627, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3417, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3209, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.3004, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2599, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2400, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2203, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.2008, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1814, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1623, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1433, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1246, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.1060, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0876, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0694, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0513, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0335, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(23.0158, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9809, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9637, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9467, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9299, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.9132, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8966, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8802, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8640, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8479, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8320, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8162, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.8006, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7851, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7697, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7545, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7395, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7245, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.7097, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6951, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6805, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6661, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6518, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6377, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6237, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.6098, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5823, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5688, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5554, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5421, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5289, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5158, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.5029, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4773, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4646, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4521, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4397, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4273, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4151, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.4030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3791, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3672, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3555, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3439, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3324, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3209, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.3096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2983, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2871, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2760, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2651, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2541, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2433, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2326, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2219, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2114, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.2009, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1905, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1801, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1699, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1597, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1496, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1396, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1296, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1198, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1100, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.1002, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0906, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0810, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0715, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0620, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0527, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0434, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0341, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0249, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0158, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(22.0068, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9978, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9889, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9800, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9712, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9625, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9538, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9452, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9367, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9282, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9197, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9113, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.9030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8948, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8865, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8784, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8703, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8622, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8542, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8463, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8384, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8306, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8228, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8150, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.8073, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7846, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7771, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7696, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7622, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7549, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7476, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7403, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7331, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7259, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7188, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7117, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.7046, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6976, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6837, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6769, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6700, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6632, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6565, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6497, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6431, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6364, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6298, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6233, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6167, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6102, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.6038, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5974, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5910, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5847, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5784, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5721, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5658, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5596, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5535, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5473, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5412, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5352, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5291, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5231, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5172, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5112, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.5053, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4995, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4936, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4878, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4820, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4763, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4705, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4648, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4592, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4536, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4479, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4424, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4368, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4313, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4258, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4204, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4149, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4095, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.4041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3988, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3934, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3881, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3829, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3776, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3724, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3672, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3620, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3569, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3517, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3466, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3416, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3365, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3315, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3265, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3215, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3165, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3116, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.3018, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2969, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2921, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2873, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2825, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2777, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2730, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2682, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2635, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2588, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2541, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2495, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2449, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2403, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2357, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2311, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2265, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2220, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2175, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2130, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2085, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.2041, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1997, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1953, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1909, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1865, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1821, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1778, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1735, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1692, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1649, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1606, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1564, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1521, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1479, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1437, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1396, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1354, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1312, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1271, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1230, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1189, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1148, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1108, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1067, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.1027, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0987, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0947, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0907, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0867, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0828, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0789, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0749, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0710, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0671, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0633, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0594, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0556, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0517, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0479, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0441, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0403, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0366, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0328, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0291, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0253, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0216, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0179, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0142, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0106, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0069, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(21.0032, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9996, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9960, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9924, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9852, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9817, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9781, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9746, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9710, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9675, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9640, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9605, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9570, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9536, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9501, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9467, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9433, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9398, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9364, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9330, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9297, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9263, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9229, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9196, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9163, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9129, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9096, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9063, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.9030, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8998, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8965, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8932, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8900, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8868, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8835, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8803, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8771, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8739, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8708, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8676, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8644, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8613, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8582, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8550, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8519, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8488, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8457, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8426, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8396, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8365, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8334, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8304, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8274, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8243, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8213, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8183, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8153, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8123, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8094, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8064, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8034, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.8005, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.7975, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.7946, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.7917, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.7888, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.7859, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n",
      "tensor(20.7830, dtype=torch.float64, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#q10 : what is the MSE over the test data?\n",
    "\n",
    "ds = torch.utils.data.TensorDataset(testX, testY)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=50, shuffle=True)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "coef = torch.zeros((10, 1), dtype=torch.float64, requires_grad=True)\n",
    "optimizer = torch.optim.SGD([coef], lr=0.000002)\n",
    "\n",
    "for epoch in range(500):\n",
    "    for trainX, trainY in dl:\n",
    "        predictions = testX @ coef\n",
    "        loss = loss_fn(predictions, testY)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(loss_fn(testX @ coef, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd4d539-10a0-444a-b923-10c62a775bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
